---
title: "NebulaNovaLifeWeekly #21 - 2025年第 34 周周报 反对AI速胜论与速败论"
date: 2025-08-22T8:22:47+08:00
draft: false
categories: ["周报"]
series: ["Weekly Report"]
series_order: 21
tags: ["weekly"]
summary: "2025年第 34 周周报（总第21期），反对AI速胜论与速败论"
---
# 反对AI速胜论与速败论

## 关于AI速胜论

随着AI工具日益便捷，我发现自己的阅读工作流也在悄然改变：从最初的复制粘贴式摘录，演变成了让AI直接总结要点（当然，这里的AI泛指生成式大语言模型）。这与近来被热议的“Vibe Coding”（氛围编程）如出一辙，我称之为“Vibe Writing”——一种假装在写作、假装在思考的状态。

有时候，看着AI“刷刷”地生成大段文字，就好像是我自己写出来的一样，这让我充满了虚假的成就感。但冷静下来想，对于这种连自己都懒得再看一遍的内容，直接公开发布，不仅是对读者的不负责任，也与倾倒信息垃圾无异。

有人将“Vibe Coding”比作玩老虎机（Slots）：当你幸运地“摇”出了想要的代码，便会获得瞬间的多巴胺奖励；如果屡试不中，则会感到沮丧。我想，AI辅助写作也是如此。甚至，不仅是内容创作，就连单纯的文本润色也充满了随机性，最终的产物往往是逻辑碎片化、七零八落的。

当然，很多人会说：“你需要用好Prompt”。但问题在于，每一次大模型更新，几乎都会导致相同Prompt的产出发生变化。反复微调Prompt的过程，更像是在调整一个随机数种子，期望能幸运地压中我们想要的结果。

在2022年AI浪潮刚刚兴起时，我曾习惯于直接贴出AI的回答来解决别人的问题。但我很快意识到了这种做法的空洞——它不仅浪费了所有人的时间，更违背了一个重要原则：“Trust, but verify”（信任，但要验证）。如果你提出了一个未经验证的思路，本质上也是在消耗他人的时间。

>用户并不懒惰，其中很多人都是经验丰富的专业人士。但当工具快速、自信、清晰地给出结果时，他们就会出于惯性，放弃思考中困难的部分，不再质疑，不再核实，从而全盘接受。

再一个大模型都使用权也是不平等的，如果你要体验市面上所有最好的模型这是一笔不小的费用。现有的Agent大多也没有看到过多的差异化。

## 关于AI速败论

当然，我也同样反对“AI速败论”。持这种观点的人倾向于将AI贬低得一无是处，凡是提到AI便一概反对。

然而，AI的强大是有目共睹的，尤其在某些特定领域。例如在编程调试（debug）时，我们常会陷入惯性思维的盲点，而AI却能直接指出错误所在。此外，在一些易于验证真伪的知识领域，AI能很好地帮助我们划定范围、提供思路。在这些场景下，大模型的“幻觉”问题所带来的负面影响相对较小。

## 总结
>用户对AI越有信心，就越不会进行独立思考。反过来，用户越不信任AI，就越可能质疑结果，验证信息，并深入思考。
所以要带质疑的使用AI，而不是盲目的信任和盲目的拒绝。
