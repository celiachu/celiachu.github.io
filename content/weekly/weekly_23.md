---
title: "NebulaNovaLifeWeekly #23 - 2025年第 36 周周报"
date: 2025-09-08T18:40:24+08:00
draft: false
categories: ["周报"]
series: ["Weekly Report"]
series_order: 23
tags: ["weekly"]
summary: "2025年第 36 周周报（总第23期），可能性与确定性——对生成式大语言模型的一点思考"
---

# 主题：可能性与确定性——对生成式大语言模型的一点思考



“交流是在寻找可能性。”

人生本身就是为了寻找各种可能性，所以我们渴望交流。每一次交流都带来思绪的碰撞，从而产生千千万万的可能性。从这个角度看，写作和阅读也是一种交流，只是把输出和输入这两个环节拆分开了，虽然交流频率没有对话那么高，但是其覆盖的范围更广，延续的时间也更久。

前面我聊过“不能迷信AI”主要是从编程角度的思考，现在，我想聊聊作为聊天工具的AI。

ChatGPT就像它的名字“Chat”一样，最初的定位就是能够对话的人工智能。然而，当我们了解到生成式大语言模型的原理后，就会明白这种“对话”或许只是我们人类的一种“幻觉”。生成式大语言模型的本质是**预测**。它的原理可以通俗地理解为：基于概率模型（如其思想源头的贝叶斯定理等），根据用户的输入来预测最可能的人类回答是什么，然后将预测结果展示在屏幕上。

为了让聊天显得真实，模型不能每次都回复同样的内容。因此，工程师人为地加入了随机性，使其产生差异和所谓的**可能性**，这就像游戏里的“伪随机”机制一样。但与此同时，为了在工程应用上获得可靠、一致的结果，又产生了“提示词工程”（Prompt Engineering）这门技术，其目的在于通过精巧的设计，强制AI按照确定的框架来工作，让**可能性坍缩为确定性**。

这就揭示了一个核心矛盾：在情感上，人们渴望通过与AI交流来激发**可能性**；但在工程实践上，人们又千方百-计地设计提示词，试图将AI的输出限定在某个**确定**的区间。AI，就在这样的矛盾之中发展。

这种对确定性的追求，在我的计算机学习生涯中也处处可见。计算机科学的许多领域本质上都是在对抗不确定性，并寻找最优解。例如，各种算法和博弈论模型的设计，通常都假设“人”是追求自身利益最大化的理性个体，因此算法里的“人”显得无比扁平。

我们可以想象一个极端的例子：十二个人的狼人杀游戏，如果每个玩家都掌握了绝对的“最优解”并严格执行，那么他们玩一百次，可能会出现完全相同的一百次对局。

当人和事一旦丧失了可能性，它就“死”掉了。